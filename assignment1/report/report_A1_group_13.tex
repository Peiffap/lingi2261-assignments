\documentclass[journal]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{minted}
\usepackage{booktabs}
\usepackage{color}

\usepackage[binary-units=true]{siunitx}

\newcommand{\py}[1]{\mintinline{python}{#1}}

\title{Artificial Intelligence (\texttt{LINGI2261}) \\ Assignment 1---Group 13}
\author{Martin Braquet, Gilles Peiffer}
\date{October 11, 2019}

\begin{document}

\maketitle

\section{Python AIMA}
\subsection{Defined Classes}
The main class, \py{Problem}, is a very general class. One thus has to subclass it in order to adapt it to these specific problems.
 The methods requiring a specific implementation are detailed below:
 \begin{itemize}
  \item \py{successor} returns a sequence of (action, state) pairs reachable from a specific state.
  \item \py{goal_test} determines when the search algorithm must stop by checking whether the current state is a goal state.
  \item The \py{__init__} method of the \py{State} class is also updated to incorporate more parameters.
  \item As explained hereinafter, the \py{__hash__} and \py{__eq__} methods of the \py{State} class are also implemented.
 \end{itemize}
This class is used inside \py{tree_search} to get access to these methods, which are considered as black boxes in the AIMA code.
 After that, one needs to create instances of this new subclass and solve them with the search functions available in \py{search.py}.
 \subsection{BFSg vs. DFSg}
 The \py{graph_search} method tries to find a solution by taking as arguments the problem to solve and an empty frontier, for which the fundamental difference is the type of this list.
 Indeed, \py{breadth_first_graph_search} uses a FIFO queue to store the nodes of the frontier in order to search the shallowest nodes first, whereas \py{depth_first_graph_search} uses a LIFO queue  (also called a stack) in order to search the deepest nodes first.
 \subsection{Instruction Analysis}
 There are two involved methods and classes detailed hereinafter.
 \begin{itemize}
 	\item \py{expand()} is a method from the \py{Node} class that outputs a list of the successors of the node given as argument.
 	\item \py{extend()} is a method from the \py{List} class that appends the list of nodes onto the list of nodes in the frontier (fringe).
 \end{itemize}
 \subsection{Graph Search vs. Tree Search}
 The \py{graph_search} method keeps track of all the visited states (as well as the states in the frontier).
 Although it requires more memory to store these states, this method has the advantage of dropping new nodes containing a state that has already been visited.
 Considering this main advantage, the graph search makes the depth-first search complete for finite state spaces and bounds the space and time complexities by the size of the state space (\(\mathcal{O}(b^d)\), where \(d\) is the depth of the shallowest goal node), which is not the case for the tree search (it is not complete since it can get stuck in a loop and the complexities are bounded by the tree size, (\(\mathcal{O}(b^m)\), where \(m\) is the maximum depth of \emph{any} node)).
 \subsection{Closed List}
 \py{closed} is a dictionary.
 Dictionaries are indexed by keys, which can be any comparable and hashable object.
 In \py{search.py}, the keys in \py{closed} are the states of the problem and the values in \py{closed} are always \py{True}.
 
 The methods involved in the search are \py{__eq__(self, other)} and \py{__hash__(self)} of the key inside a dictionary.
 One must thus override these methods in the \py{State} class in order to make this class comparable and hashable.
 \py{__eq__(self, other)} returns \py{True} or \py{False} based on the comparison between \py{self} and \py{other}.
 Because the hashed value is uniquely defined if one knows the grid, the value of both grids is compared. 
 
 \py{__hash__(self)} returns the hash value (an integer) of an object (here an instance of the \py{State} class) defined in order to meet our specific needs.
 In order to keep the same hash for a class, one cannot change the mutable variables of the class as soon as the dictionary has applied the hash function for this object.
 This is verified in the case at hand since the class is hashed based on the value of the grid, which is never changed after its creation.
 The hash of the grid is sufficient to completely describe this class: since each tile can have 3 values, one can store each tile on 2 bits (00 for a blank space, 01 for a white knight and 10 for a dark knight).
 Then, one can just sum all the values according to a formula which combines position and symbol for each tile in order to get a unique hash associated to a specific grid.
 \subsection{Symmetrical states}
 Since the board and the moves of the knight are symmetrical with respect to multiple axes of symmetry, two symmetrical states will lead to two symmetrical solutions (if they exist).
 One's goal is thus to avoid visiting symmetrical states multiple times. 
 In order to achieve this, care must be taken to define the hashing function and the equality function in such a way that two symmetrical states will have the same hash.
 This way, once one of the symmetrical states has been visited, the closed list contains its hash.
 The next time the algorithm encounters this state or any other state in its symmetry group, it will be considered as having already been visited.
 
 The analysis of the explored nodes are detailed below for three different algorithms on a $7\times7$ grid.
 Case 1 is run without symmetrical states.
 Case 2 has an \py{__eq__} method that returns \py{True} for symmetrical states, whereas the \py{__hash__} method is based on the status of the grid and thus returns a different hash for these symmetrical states.
 Thus, this second method does not remove all the symmetrical states.
 Case 3 uses a hash that is only based on the number of visited tiles, this is the only information guaranteeing that two symmetrical states will have the same hash. One can notice that this third method is slower than the two others since there are more states having the same hash, the dictionary lookup time is thus affected.
 
\begin{table}[!hbtp]
	\centering
\begin{tabular}{ccccc} 
 \toprule
  Case & Time (\si{\second}) & Nodes\\
  \midrule
 1 & 2.04 & 24198\\
 2 & 1.39 & 18876\\
 3 & 2.72 & 13692\\
 \bottomrule\\
\end{tabular}
\caption{Computing time and number of explored nodes for different configurations of the symmetrical algorithms.}
\end{table}

\section{The Knightâ€™s Tour Problem}
\subsection{Description}
The knight can move to at most 8 different tiles per move (according to the legal moves of a knight on a chessboard, while taking into account the fact the knight cannot leave said board).
 One can thus consider a branching factor of 8.
 \subsection{Problem Analysis}
 The number of tiles is \(n_{\textnormal{cols}} \times n_{\textnormal{\vphantom{l}rows}} = 25\) in the template board, meaning that the tree is not excessively deep compared to its breadth.
 \begin{enumerate}
  \item A breadth-first search in this case is not efficient because the branching factor is quite large.
  Because the number of moves is the same for a given chess board, one knows that the depth of the solution is the same for all initial positions: \(d = n_{\textnormal{cols}} \times n_{\textnormal{\vphantom{l}rows}} - 1\).
  This information leads to an easy \py{goal_test} implementation, since one can simply check that the number of visited tiles (given as a paramer of the \py{State} class) is equal to \(d\).
  The depth-first search is quite efficient when the successors are sorted, even according to an uninformed heuristic, as detailed in the next paragraphs.
  \item The graph search calls the \py{__eq__(self, other)} and \py{__hash__(self)} methods, which loop on each tile of the board.
  This implies too many computations to check if a new state has already been visited.
  This observation is validated by the table of computation times available below.
  Because the number of nodes reached up to the solution is very small with a tree search, the increased computation time due to dictionary lookups does nullify (to some extent) the gain offered by having a reduced number of reached nodes for the graph search.
  The tree search is thus the best algorithm for this problem.
 \end{enumerate}
 \subsection{Implementation}
 The majority of the work for this implementation was done on the \py{successor(self, state)} method of the \py{Knight} class.
 This method first creates a list of the next available positions (successors) based on the current position (state).
 Then, the specificity of the algorithm is that the successors are sorted according to their proximity to the nearest border of the chessboard, so as to explore the most remote successors first.
 In order to do this, the \py{border(position)} method which computes the distance to the nearest border for all the possible successors of the current state.
 The knight will thus go through the tiles that are the most difficult to reach (far from the center of the board).
 If the knight manages to travel around the borders without reaching a dead end, reaching the center of the board is much easier part (significantly increasing the odds of finding a solution).
 It is worth noting that this method is not considered as an informed search since it is only based on the states of the successors, and not on the nodes deeper in the tree.
 
 With this classification, the knight sometimes even directly finds the solution (having explored only 25 nodes).
 This corroborates the fact that this easy problem is not very dependent on the first couple of moves of the knight because there are multiple solutions for any given initial position.
 
 The list of successors is sorted in descending order since the yield method gives the states one-by-one, it gives thus the state which is closest to the border, last.
 This state is then on top of the stack and checked first when \py{frontier} is a LIFO queue.
 However, without changing the methods in \py{search.py}, one cannot sort the successors optimally for both the depth-first and breadth-first searches at the same time: for the breadth-first search (FIFO queue), the successors are sorted in the wrong order in \py{frontier} and will thus begin to check the states (in the same layer) which are closest to the centre.
 Since the depth-first search is faster when no classification is applied, the authors elected to sort in the right order for the depth-first search, in order to maximize the fastest algorithm.
 %The most important work has been achieved for the \py{successor(self, state)} method of the \py{Knight} class. It first consists to create a list of the next available positions (successors) based on the current position (state). Then, the specificity of our very efficient algorithm is that we \textbf{sort the successors by ascending number of their own successors}. Indeed, we use the \py{nsucc(position)} method which computes the number of successors for all the possible successors of the current state. The knight will thus go through the tiles that are the most difficult to reach (few successors), these are around the corners and borders of the board. If it manages to travel around the borders without being stucked, reaching the center of the board is an easier part (significantly increasing his chances to find a solution).
 \subsection{Experiments}
 The computation times for the four algorithms on each of the 10 instances are detailed in Table~\ref{time1}.\footnote{Experiments were run on an Early 2015 MacBook Pro, running macOS Sierra 10.12.6, using a \SI{2.9}{\giga\hertz} Intel Core i5 processor, with \SI{8}{\giga\byte} of \SI{1867}{\mega\hertz} DDR3 RAM and an Intel Iris Graphics 6100 GPU.} 

\begin{table}[!hbtp]
	\centering
\begin{tabular}{ccccc} 
 \toprule
  Inst. & DFSt (\si{\milli\second}) & BFSt (\si{\second}) & DFSg (\si{\milli\second}) & BFSg (\si{\second})\\
  \midrule
 1 & 1.68 (58) & 46.5 (1453934) & 3.18 (58) & 4.63 (38619) \\
 2 & 0.731 (25) & 55.5 (1734776) & 1.24 (25) & 4.72 (42324) \\
 3 & 1.68 (58) & 46.6 (1465422) & 2.44 (58) & 9.47 (49779) \\
 4 & 1.55 (58) & 48.4 (1465422) & 2.99 (58) & 6.82 (50335) \\
 5 & 0.727 (25) & 20.6 (641514) & 1.22 (25) & 2.63 (28144) \\
 6 & 1.01 (25) & 55.4 (1734776) & 1.45 (25) & 5.57 (39201) \\
 7 & 2.17 (58) & 47.9 (1465422) & 2.45 (58) & 6.28 (47617) \\
 8 & 1.38 (58) & 48.6 (1465422) & 2.51 (58) & 6.60 (47888) \\
 9 & 1.37 (58) & 47.6 (1453934) & 2.64 (58) & 5.75 (42292) \\
 10& 1.36 (58) & 46.5 (1453934) & 2.34 (58) & 5.52 (43656) \\
 \bottomrule\\
\end{tabular}
\caption{Times are given with 3 significant figures in the unit indicated next to the method and with the number of explored nodes between parentheses.}
\label{time1}
\end{table}

 \subsection{Submission}
 The program is uploaded on INGInious and passes 15/15 tests.
 \subsection{Conclusion}
 \begin{enumerate}
  \item Based on the computation time and the number of reached nodes, it is clear that the depth-first search is far more efficient than the breadth-first search (thanks in part to the efficient sort of the successors). Also, one can notice that the graph search is slightly slower due to the comparison required by the dictionary, as predicted by the theoretical approach.
  Thus, the experimental results are indeed consistent with our expectations.
  \item The depth-first tree search is the most promising for this problem, but it can most likely be improved using additional algorithms covered during the lecture on uninformed search.
  A depth-limited search could be very interesting if one sets the limit at the (known) depth of the goal.
  On the other hand, the iterative deepening search will not be particularly efficient since we know the depth of the goal.
  Finally, a bidirectional search will also fit this problem since the final states are known (all tiles are occupied by a black knight, except one which is white).
  It should significantly reduce the number of explored nodes, especially for a breadth-first search.
  
  But obviously, these possible improvements will not surpass our depth-first tree search algorithm if this one finds directly the solution (which means with \(n_{\textnormal{cols}} \times n_{\textnormal{\vphantom{l}rows}}\) explored nodes) as is the case for some initial positions.
 \end{enumerate}
\end{document}
